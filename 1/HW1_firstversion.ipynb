{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def union2(p1,p2):\n",
    "    '''This def will return the union of two binary searches''' \n",
    "    L3 = [max(l1, l2) for l1, l2 in zip(p1, p2)]\n",
    "    return(L3)\n",
    "def intersection2(p1,p2):\n",
    "    '''This def will return the intersection of two binary searches'''\n",
    "    L3 = [min(l1, l2) for l1, l2 in zip(p1, p2)]\n",
    "    return(L3)\n",
    "def tokenize(search):\n",
    "    '''This def tokenize, lower csae, and stem all the strings'''\n",
    "    search_token = word_tokenize(search) #Tokenize\n",
    "    search_token = [i.lower() for i in search_token] # Lower Case\n",
    "    search_token = [porter.stem(word) for word in search_token] #Stem\n",
    "    return(search_token)\n",
    "def extractkeys(tokens):\n",
    "    '''This token will extract the operation sumbols and match the keys of each tokens with our binary matrix'''\n",
    "    unionwords = ['or','and']\n",
    "    operations = [word for word in unionwords if word in tokens] #operation\n",
    "    keys = [word for word in tokens if word not in unionwords and word in [*mydict.keys()]] #keys\n",
    "    return(operations, keys)\n",
    "def operation(p1,p2,operation):\n",
    "    '''This def does the union and intersection, given the binary data, and the operation types (or, and)'''\n",
    "    out=list()\n",
    "    if operation == ['or']:\n",
    "        out=union2(p1,p2)\n",
    "    elif operation == ['and']:\n",
    "        out=intersection2(p1,p2)\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function prepro in module __main__:\n",
      "\n",
      "prepro(docs='docs.txt')\n",
      "    This is the preprocessing module, whitch given a txt document that each new line is one document, and each line starts with the documentID. \n",
      "    This Def will return the term-document incidence matrix\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepro(docs = \"docs.txt\"):\n",
    "    ''' This is the preprocessing module, whitch given a txt document that each new line is one document, and each line starts with the documentID. \n",
    "    This Def will return the term-document incidence matrix'''\n",
    "    infile = open(docs,'r')\n",
    "    docs=infile.readlines()\n",
    "    docs=[i.strip() for i in docs] #removing the \\n\n",
    "    docs=[i.lower() for i in docs] #Lower Case\n",
    "\n",
    "    tokenized = [word_tokenize(docs[i]) for i in range(len(docs))]\n",
    "    [i.pop(0) for i in tokenized] # Removing the ID\n",
    "\n",
    "    porter = PorterStemmer()\n",
    "    stemmed=[]\n",
    "    for i in range(len(docs)):\n",
    "        stem = [porter.stem(word) for word in tokenized[i]]\n",
    "        stemmed.append(stem)\n",
    "\n",
    "    tokens = set(x for l in stemmed for x in l)\n",
    "    mydict = dict()\n",
    "    for el in tokens:\n",
    "        mydict[el]=[stemmed[i].count(el) for i in range(len(docs))]\n",
    "    return(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(search,mydict):\n",
    "    '''This def, takes the operation search (i.e. patiens and drugs), and term-document incidence matrix and finds the search result. The search results are shown in a binary list, which each value of this arry represent document (starting from the 1st document to the last.)'''\n",
    "    inside=re.findall('\\((.*?)\\)',search)\n",
    "    outside = re.findall('\\)(.*?)\\(',search)\n",
    "    search_token = tokenize(search)\n",
    "    operations, search_keys = extractkeys(search_token)\n",
    "\n",
    "    if len(search_keys)==1:\n",
    "        result['operat']=mydict[search_keys[0]]\n",
    "    if len(search_keys)==2:  \n",
    "        result['operat']=operation(mydict[search_keys[0]],mydict[search_keys[1]],operations)\n",
    "\n",
    "    if len(search_keys) > 2:\n",
    "        for i in range(len(inside)):\n",
    "            tokens = tokenize(inside[i])\n",
    "            operations_inside, keys_inside = extractkeys(tokens)\n",
    "            result[i]=operation(mydict[keys_inside[0]],mydict[keys_inside[1]],operations_inside)\n",
    "\n",
    "        if outside:\n",
    "            operations_outside = [tokenize(i) for i in outside]\n",
    "            result['operat'] = operation(result[0], result[1],operations_outside[0])\n",
    "            if len(operations_outside) > 1:\n",
    "                print (outside)\n",
    "                print (operations_outside)\n",
    "                for j in range(1,len(operations_outside)):\n",
    "                    result['operat'] = operation(result['operat'], result[j+1],operations_outside[j])\n",
    "        else:\n",
    "            result['operat']=result[0]\n",
    "        #First:\n",
    "        if search_token[0]!='(':\n",
    "            result['operat']=operation(result['operat'], mydict[search_token[0]],[search_token[1]])\n",
    "            \n",
    "        #Last:    \n",
    "        if search_token[-1]!=')':\n",
    "            result['operat']=operation(result['operat'], mydict[search_token[-1]],[search_token[-2]])\n",
    "    return(result['operat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process2(search,mydict):\n",
    "    '''This def, takes the operation search (i.e. patiens and drugs), and term-document incidence matrix and finds the search result. The search results are shown in a binary list, which each value of this arry represent document (starting from the 1st document to the last.)'''\n",
    "    inside=re.findall('\\((.*?)\\)',search)\n",
    "    outside = re.findall('\\)(.*?)\\(',search)\n",
    "    search_token = tokenize(search)\n",
    "    operations, search_keys = extractkeys(search_token)\n",
    "\n",
    "    if len(search_keys)==1:\n",
    "        result['operat']=mydict[search_keys[0]]\n",
    "    if len(search_keys)==2:  \n",
    "        result['operat']=operation(mydict[search_keys[0]],mydict[search_keys[1]],operations)\n",
    "\n",
    "    if len(search_keys) > 2:\n",
    "        for i in range(len(inside)):\n",
    "            tokens = tokenize(inside[i])\n",
    "            operations_inside, keys_inside = extractkeys(tokens)\n",
    "            result[i]=operation(mydict[keys_inside[0]],mydict[keys_inside[1]],operations_inside)\n",
    "        \n",
    "        #First:\n",
    "        if search_token[0]!='(':\n",
    "            result['operat']=operation(result[0], mydict[search_token[0]],[search_token[1]])\n",
    "        else:\n",
    "            result['operat']=result[0]\n",
    "        print(result['operat'])\n",
    "        #Middle:\n",
    "        \n",
    "        if outside:\n",
    "            operations_outside = [tokenize(i) for i in outside]\n",
    "            for j in range(0,len(operations_outside)):\n",
    "                result['operat'] = operation(result['operat'], result[j+1],operations_outside[j])\n",
    "        #Last:    \n",
    "        if search_token[-1]!=')':\n",
    "            result['operat']=operation(result['operat'], mydict[search_token[-1]],[search_token[-2]])\n",
    "    return(result['operat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "unionwords = ['or','and']\n",
    "result=dict()\n",
    "# search = 'treatment  or (schizophrenia and drugs) and (treatment and drugs) and drugs'\n",
    "# search = '(treatment and drugs) and drugs'\n",
    "def main():\n",
    "    search=input(\"give the operation:\")\n",
    "    mydict = prepro()\n",
    "    result = process2(search,mydict)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give the operation:treatment  or (schizophrenia and drugs) or (treatment and drugs) and drugs\n",
      "[1, 1, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()\n",
    "#treatment  or (schizophrenia and drugs) or (treatment and drugs) and drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "operation(p1,p2,operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unionwords = ['or','and']\n",
    "# operations = [word for word in unionwords if word in search_token  ]\n",
    "# keys = [word for word in search_token if word not in unionwords and word in [*mydict.keys()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doc2 new approach for treatment of schizophrenia'"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doc1', 'doc2', 'doc3', 'doc4']"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['breakthrough', 'drug', 'for', 'schizophrenia'],\n",
       " ['new', 'approach', 'for', 'treatment', 'of', 'schizophrenia'],\n",
       " ['new', 'hope', 'for', 'schizophrenia', 'patient'],\n",
       " ['new', 'schizophrenia', 'drug']]"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approach',\n",
       " 'breakthrough',\n",
       " 'drug',\n",
       " 'for',\n",
       " 'hope',\n",
       " 'new',\n",
       " 'of',\n",
       " 'patient',\n",
       " 'schizophrenia',\n",
       " 'treatment'}"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approach': [0, 1, 0, 0],\n",
       " 'breakthrough': [1, 0, 0, 0],\n",
       " 'drug': [1, 0, 0, 1],\n",
       " 'for': [1, 1, 1, 0],\n",
       " 'hope': [0, 0, 1, 0],\n",
       " 'new': [0, 1, 1, 1],\n",
       " 'of': [0, 1, 0, 0],\n",
       " 'patient': [0, 0, 1, 0],\n",
       " 'schizophrenia': [1, 1, 1, 1],\n",
       " 'treatment': [0, 1, 0, 0]}"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatment  or (schizophrenia and drugs) and (treatment and drugs) and drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mydict = dict((el,[stemmed[0].count(el),stemmed[1].count(el),stemmed[2].count(el),stemmed[3].count(el)]) for el in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict['breakthrough'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0]"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict['for']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def intersection(p1,p2):\n",
    "    mydict['intersection']=mydict[p1].copy()\n",
    "    for i in range(len(docs)):\n",
    "        if mydict[p1][i] == mydict[p2][i] == 1:\n",
    "            mydict['intersection'][i]=1\n",
    "        else:\n",
    "            mydict['intersection'][i]=0\n",
    "    return(mydict['intersection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection('schizophrenia','drug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def union(p1,p2):\n",
    "    mydict['union']=mydict[p1].copy()\n",
    "    for i in range(len(docs)):\n",
    "        if mydict[p2][i] == 1:\n",
    "            mydict['union'][i]=1\n",
    "    return(mydict['union'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union('schizophrenia','drug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict['schizophrenia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict['drug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict['treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict['schizophrenia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unioninter(p1,p2,p3):\n",
    "    union(p1,p2)\n",
    "    intersection('union',p3)\n",
    "    return(mydict['intersection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unioninter('drug' , 'treatment' , 'schizophrenia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are you looking for? a;d\n"
     ]
    }
   ],
   "source": [
    "search = input(\"what are you looking for? \")\n",
    "# drug OR treatment AND schizophrenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search = 'treatment  or (schizophrenia and drugs) and (treatment and drugs) and drugs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['schizophrenia and drugs', 'treatment and drugs']"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inside = search[search.find(\"(\")+1:search.find(\")\")]\n",
    "import re\n",
    "inside=re.findall('\\((.*?)\\)',search)\n",
    "inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "left=re.match('(.*?)\\(',search)\n",
    "outside = re.findall('\\)(.*?)\\(',search)\n",
    "outside\n",
    "# [tokenize(i) for i in outside]\n",
    "if outside:\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_token = word_tokenize(search)\n",
    "search_token=[i.lower() for i in search_token] #Lower Case\n",
    "search_token = [porter.stem(word) for word in search_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left_parant = [ word for word in search_token[0:2] if word in ['(',')']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(search):\n",
    "    search_token = word_tokenize(search) #Tokenize\n",
    "    search_token = [i.lower() for i in search_token] # Lower Case\n",
    "    search_token = [porter.stem(word) for word in search_token] #Stem\n",
    "    return(search_token)\n",
    "def extractkeys(tokens):\n",
    "    unionwords = ['or','and']\n",
    "    operations = [word for word in unionwords if word in tokens] #operation\n",
    "    keys = [word for word in tokens if word not in unionwords and word in [*mydict.keys()]] #keys\n",
    "    return(operations, keys)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if search_token[0]!='(':\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['treatment', 'schizophrenia', 'drug', 'treatment', 'drug', 'drug']"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unionwords = ['or','and']\n",
    "operations = [word for word in unionwords if word in search_token  ]\n",
    "keys = [word for word in search_token if word not in unionwords and word in [*mydict.keys()]]\n",
    "\n",
    "\n",
    "operations\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and']"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tokenize(sina[0])\n",
    "# print(a)\n",
    "# keys = [word for word in a if word not in unionwords and word in [*mydict.keys()]]\n",
    "# print(keys)\n",
    "c,d =extractkeys(a)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and']\n",
      "[1, 1, 1, 1] [1, 1, 0, 0]\n",
      "[1, 1, 0, 0]\n",
      "[1, 1, 0, 0] [0, 1, 0, 0] or\n",
      "[1, 1, 0, 0]\n",
      "[1, 1, 0, 0] [1, 0, 0, 1] ['drug'] ['and']\n",
      "[1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "docs=dict()\n",
    "if len(keys)==1:\n",
    "    docs['one_word']=mydict[keys[0]]\n",
    "if len(keys)==2 and operations == ['or']:\n",
    "    docs['one_union']=union(keys[0],keys[1])\n",
    "if len(keys)==2 and operations == ['and']:\n",
    "    docs['one_inter']=intersection(keys[0],keys[1])\n",
    "\n",
    "if len(keys) > 2:\n",
    "    for i in range(len(inside)):\n",
    "        tokens = tokenize(inside[i])\n",
    "        operations_inside, keys_inside = extractkeys(tokens)\n",
    "        if operations_inside == ['or']:\n",
    "            docs[i]=union(keys_inside[0],keys_inside[1])\n",
    "        if operations_inside == ['and']:\n",
    "            docs[i]=union(keys_inside[0],keys_inside[1])\n",
    "\n",
    "    if outside:\n",
    "        operations_outside = [tokenize(i) for i in outside]\n",
    "        print(operations_outside[0])\n",
    "        print(docs[0], docs[1])\n",
    "        docs['operat'] = operation(docs[0], docs[1],operations_outside[0])\n",
    "        print(docs['operat'])\n",
    "        if len(operations_outside) > 1:\n",
    "            for j in range(1,len(operations_outside)):\n",
    "                docs['operat'] = operation(docs['operat'], docs[j+1],operations_outside[j])     \n",
    "            \n",
    "            #First:\n",
    "    if search_token[0]!='(':\n",
    "        print(docs['operat'],mydict[search_token[0]],search_token[1])\n",
    "        \n",
    "        docs['operat']=operation(docs['operat'], mydict[search_token[0]],[search_token[1]])\n",
    "        print(docs['operat'])\n",
    "        \n",
    "#         docs['first']=union2(search_token[0],docs[0])\n",
    "#     elif search_token[0]!='(' and search_token[1] == ['and']:\n",
    "#         docs['first']=intersection2(search_token[0],docs[0])\n",
    "\n",
    "            #Last:    \n",
    "    if search_token[-1]!=')':\n",
    "        print(docs['operat'],mydict[search_token[-1]],[search_token[-1]],[search_token[-2]])\n",
    "        docs['operat']=operation(docs['operat'], mydict[search_token[-1]],[search_token[-2]])\n",
    "        print(docs['operat'])\n",
    "        \n",
    "#     if search_token[-1]!=')' and search_token[-2] == ['or']:\n",
    "#         docs['last']=union2(search_token[-1],docs[i])\n",
    "#     elif search_token[-1]!='(' and search_token[-2] == ['and']:\n",
    "#         docs['last']=intersection2(search_token[-1],docs[i])\n",
    "        \n",
    "    \n",
    "        \n",
    "#         if 'first' in docs.keys():\n",
    "#             docs['operat'] = operation(docs['first'], docs[1],operations_outside[0])\n",
    "#         else:\n",
    "#             docs['operat'] = docs['first']\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0]"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict[search_token[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1, 1, 1, 1], 1: [1, 1, 0, 0], 'operat': [1, 0, 0, 0]}"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 3)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations_outside=[1,2,3]\n",
    "range(len(operations_outside))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if 0 in docs.keys():\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs['operat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def operation(p1,p2,operation):\n",
    "    out=list()\n",
    "    if operation == ['or']:\n",
    "        out=union2(p1,p2)\n",
    "    elif operation == ['and']:\n",
    "        out=intersection2(p1,p2)\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operation([0,0,0,0],[1,2,0,2],['and'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs['one_inter']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
