{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def invertindex(docs=\"docs.txt\"):\n",
    "    '''This fundtion will take the document txt folder (each line should indicate new document and the first token is document name)\n",
    "    It will return the inverted index and the tokenized (and stemed) version of all the documents'''\n",
    "    stemmed=[]\n",
    "    infile = open(docs,'r')\n",
    "    docs=infile.readlines()\n",
    "    docs=[i.strip() for i in docs] #removing the \\n\n",
    "    docs=[i.lower() for i in docs] #Lower Case\n",
    "    tokenized = [word_tokenize(docs[i]) for i in range(len(docs))]\n",
    "    [i.pop(0) for i in tokenized] # Removing the ID\n",
    "    for i in range(len(docs)):\n",
    "        stem = [porter.stem(word) for word in tokenized[i]]\n",
    "        stemmed.append(stem)\n",
    "    index=dict()\n",
    "    for i in range(len(stemmed)):\n",
    "        for word in set(stemmed[i]):\n",
    "            if word in index:\n",
    "                index[word].append(i+1)\n",
    "            else:\n",
    "                index[word]=[i+1]\n",
    "    return(index,stemmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def positionalintersect(p1,p2,k,invertedindex,tokenized):\n",
    "    '''This function is for proximity intersection of postings lists p1 and p2. The function finds places where the two terms appear within k words of each other and returns a list of triples giving docID and the term position in p1 and p2.'''\n",
    "    answer=list()\n",
    "    shareddoc = set(index[p1]) & set(index[p2]) #Find the shared documents set\n",
    "    for i in shareddoc :\n",
    "    #     p1index=tokenized[i-1].index(p1)\n",
    "    #     p2index=tokenized[i-1].index(p2)   \n",
    "        p1indices = [i for i, x in enumerate(tokenized[i-1]) if x == p1]\n",
    "        p2indices = [i for i, x in enumerate(tokenized[i-1]) if x == p2]\n",
    "        l=list()\n",
    "        for pp1 in p1indices:\n",
    "            for pp2 in p2indices:\n",
    "                while True:\n",
    "                    if abs(pp1-pp2) <= k:\n",
    "                        print(abs(pp1-pp2))\n",
    "                        l.append(pp2)\n",
    "                    elif pp2 > pp1:\n",
    "                        break\n",
    "                    while len(l)!=0 and abs(l[-1] - pp1) > k:\n",
    "                        l.pop()\n",
    "                    for s in l:\n",
    "                        answer.append((i, pp1, s))\n",
    "                    break\n",
    "    return(answer)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def querytokenizer(query):\n",
    "    '''Given query with following formt: \"p1 /k p2\"\n",
    "    This function will return stemed strings of p1 and p2, and k as a intiger'''\n",
    "    search_token = word_tokenize(query) #Tokenize\n",
    "    search_token = [i.lower() for i in search_token] # Lower Case\n",
    "    search_token = [porter.stem(word) for word in search_token] #Stem\n",
    "    #Extract k\n",
    "    r = re.compile(\"\\/\\d+\")\n",
    "    m = r.findall(query)\n",
    "    k=int(m[0].replace(\"/\", \"\"))\n",
    "    p1=search_token[0]\n",
    "    p2=search_token[-1]\n",
    "    return(p1,p2,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submain(docs = \"docs.txt\"):\n",
    "    query=input(\"Please give me the query (format: p1 /k p2)\")\n",
    "    invertedindex,tokenized =invertindex(docs)\n",
    "    p1,p2,k = querytokenizer(query)\n",
    "    answer=positionalintersect(p1,p2,k,invertedindex,tokenized)\n",
    "    print(answer)\n",
    "    return(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    while True:\n",
    "        submain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please give me the query (format: p1 /k p2)schizophrenia /4 drug\n",
      "2\n",
      "1\n",
      "[(1, 3, 1), (4, 1, 2)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Users/sinaehsani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sinaehsani/anaconda3/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sinaehsani/anaconda3/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \"\"\"\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/sinaehsani/anaconda3/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-58ca95c5b364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-135-aa2b6e411653>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msubmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-132-2eec6a75a532>\u001b[0m in \u001b[0;36msubmain\u001b[0;34m(docs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"docs.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please give me the query (format: p1 /k p2)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0minvertedindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenized\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0minvertindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquerytokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0manswer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositionalintersect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minvertedindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sinaehsani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sinaehsani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[23,24,25].pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def positionalintersect2(p1,p2,k,invertedindex,tokenized):\n",
    "    '''This function is for proximity intersection of postings lists p1 and p2. The function finds places where the two terms appear within k words of each other and returns a list of triples giving docID and the term position in p1 and p2.'''\n",
    "    answer=list()\n",
    "    shareddoc = set(index[p1]) & set(index[p2]) #Find the shared documents set\n",
    "    for i in shareddoc :\n",
    "    #     p1index=tokenized[i-1].index(p1)\n",
    "    #     p2index=tokenized[i-1].index(p2)   \n",
    "        p1indices = [i for i, x in enumerate(tokenized[i-1]) if x == p1]\n",
    "        p2indices = [i for i, x in enumerate(tokenized[i-1]) if x == p2]\n",
    "        l=list()\n",
    "        for pp1 in p1indices:\n",
    "            for pp2 in p2indices:\n",
    "                while True:\n",
    "                    if 0 < pp2-pp1 <= k:\n",
    "                        print(abs(pp1-pp2))\n",
    "                        l.append(pp2)\n",
    "                    elif pp1 > pp2:\n",
    "                        break\n",
    "                    elif pp2 > pp1:\n",
    "                        break\n",
    "                    while len(l)!=0 and abs(l[-1] - pp1) > k:\n",
    "                        l.pop()\n",
    "                    for s in l:\n",
    "                        answer.append((i, pp1, s))\n",
    "                    break\n",
    "    return(answer)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submain(docs = \"docs.txt\"):\n",
    "    query=input(\"Please give me the query (format: p1 /k p2)\")\n",
    "    qtype=input(\"Which type of query do you want? (a for part 1, else for part 2(directional))\")\n",
    "    invertedindex,tokenized =invertindex(docs)\n",
    "    p1,p2,k = querytokenizer(query)\n",
    "    if qtype == \"a\":\n",
    "        answer=positionalintersect(p1,p2,k,invertedindex,tokenized)\n",
    "    else:\n",
    "        answer=positionalintersect2(p1,p2,k,invertedindex,tokenized)\n",
    "    print(answer)\n",
    "    return(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please give me the query (format: p1 /k p2)breakthrough /2 new\n",
      "Which type of query do you want? (a for part 1, else for part 2(directional))s\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['breakthrough', 'drug', 'for', 'schizophrenia'],\n",
       " ['new', 'approach', 'for', 'treatment', 'of', 'schizophrenia'],\n",
       " ['new', 'hope', 'for', 'schizophrenia', 'patient'],\n",
       " ['new', 'schizophrenia', 'drug']]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 1, 3)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index,tokenized=invertindex(\"docs.txt\")\n",
    "p2='schizophrenia'\n",
    "p1='drug'\n",
    "k=2\n",
    "positionalintersect2(p1,p2,k,index,tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('schizophrenia', 'drug', 221)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "querytokenizer(\"schizophrenia /221 drug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = re.compile(\"\\/\\d+\")\n",
    "m = r.findall(\"schizophrenia  /22  drug\") #extract k\n",
    "k=int(m[0].replace(\"/\", \"\"))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['schizophrenia', '/2', 'drug']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "querytokenizer(\"schizophrenia /2 drug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "3\n",
      "1\n",
      "[(2, 5, 0), (3, 3, 0), (4, 1, 0)]\n"
     ]
    }
   ],
   "source": [
    "index,tokenized=invertindex(\"docs.txt\")\n",
    "answer = positionalintersect('schizophrenia','new',5,index,tokenized)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 3, 4}\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "index,tokenized=invertindex(\"docs.txt\")\n",
    "p1='schizophrenia'\n",
    "p2='new'\n",
    "k=3\n",
    "\n",
    "answer=list()\n",
    "shareddoc = set(index[p1]) & set(index[p2]) #Find the shared documents set\n",
    "print (shareddoc)\n",
    "for i in shareddoc :\n",
    "#     p1index=tokenized[i-1].index(p1)\n",
    "#     p2index=tokenized[i-1].index(p2)   \n",
    "    p1indices = [i for i, x in enumerate(tokenized[i-1]) if x == p1]\n",
    "    p2indices = [i for i, x in enumerate(tokenized[i-1]) if x == p2]\n",
    "    l=list()\n",
    "    for pp1 in p1indices:\n",
    "        for pp2 in p2indices:\n",
    "            while True:\n",
    "                if abs(pp1-pp2) <= k:\n",
    "                    l.append(pp2)\n",
    "                    print(l)\n",
    "                elif pp2 > pp1:\n",
    "                    print('yes')\n",
    "                    break\n",
    "                while len(l)!=0 and abs(l[-1] - pp1) > k:\n",
    "                    l.pop()\n",
    "                for s in l:\n",
    "                    answer.append((i, pp1, s))\n",
    "                break\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 3, 0), (4, 1, 0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['breakthrough', 'drug', 'for', 'schizophrenia'],\n",
       " ['new', 'approach', 'for', 'treatment', 'of', 'schizophrenia'],\n",
       " ['new', 'hope', 'for', 'schizophrenia', 'patient'],\n",
       " ['new', 'schizophrenia', 'drug']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['breakthrough', 'drug', 'for', 'schizophrenia'],\n",
       " ['new', 'approach', 'for', 'treatment', 'of', 'schizophrenia'],\n",
       " ['new', 'hopes', 'for', 'schizophrenia', 'patients'],\n",
       " ['new', 'schizophrenia', 'drug']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index,tokenized=invertindex(\"docs.txt\")\n",
    "# tokenized[0].append('breakthrough')\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breakthrough', 'drug', 'for']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[0].pop()\n",
    "tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = [i for i, x in enumerate(tokenized[0]) if x == \"breakthrough\"]\n",
    "print(indices)\n",
    "while i in indices:\n",
    "    print (i)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in indices:\n",
    "    while True:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in set(index['new']) & set(index['approach']):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(index['new']) & set(index['breakthrough'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approach': [2],\n",
       " 'breakthrough': [1],\n",
       " 'drug': [1, 4],\n",
       " 'for': [1, 2, 3],\n",
       " 'hopes': [3],\n",
       " 'new': [2, 3, 4],\n",
       " 'of': [2],\n",
       " 'patients': [3],\n",
       " 'schizophrenia': [1, 2, 3, 4],\n",
       " 'treatment': [2]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word='breakthrough'\n",
    "index[word]=[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'drug' in index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index['drug'].append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approach': [2],\n",
       " 'breakthrough': [1],\n",
       " 'drug': [1, 4],\n",
       " 'for': [1, 2, 3],\n",
       " 'hopes': [3],\n",
       " 'new': [2, 3, 4],\n",
       " 'of': [2],\n",
       " 'patients': [3],\n",
       " 'schizophrenia': [1, 2, 3, 4],\n",
       " 'treatment': [2]}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=(i for i in range(len(tokenized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x10ef23d58>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
